{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minnesota T-Pups Plus/Minus Modeling\n",
    "\n",
    "##### By: Mitch Brinkman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge #ordinary linear regression + w/ ridge regularization\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bball_func import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_table = pd.read_pickle('final_data_table.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA team Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables from all the NBA teams\n",
    "\n",
    "dummies = pd.get_dummies(avg_data_table['opp'])\n",
    "avg_data_table = pd.concat([avg_data_table,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_integers(['ATL', 'BOS', 'BRK', 'CHA', 'CHI', 'CHO', 'CLE', 'DAL', 'DEN', 'DET',\n",
    "       'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'NOH', 'NOP',\n",
    "       'NYK', 'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC', 'SAS', 'TOR', 'UTA',\n",
    "       'WAS'],avg_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = avg_data_table.loc[:,['ATL', 'BOS', 'BRK', 'CHA', 'CHI', 'CHO', 'CLE', 'DAL', 'DEN', 'DET',\n",
    "       'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'NOH', 'NOP',\n",
    "       'NYK', 'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC', 'SAS', 'TOR', 'UTA',\n",
    "       'WAS']]\n",
    "\n",
    "dummy_y = avg_data_table['plus_minus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the train-test split for dummy variables\n",
    "\n",
    "dummy_X_train_val, dummy_X_test, dummy_y_train_val, dummy_y_test = train_test_split(dummy_X, dummy_y, test_size=0.2,random_state=21)\n",
    "X_train, X_val, y_train, y_val = train_test_split(dummy_X_train_val, dummy_y_train_val, test_size=.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking on validation shape\n",
    "\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns1 = ['ATL', 'BOS', 'BRK', 'CHA', 'CHI', 'CHO', 'CLE', 'DAL', 'DEN', 'DET',\n",
    "       'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'NOH', 'NOP',\n",
    "       'NYK', 'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC', 'SAS', 'TOR', 'UTA',\n",
    "       'WAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running Lasso to check which dummy variables are significant enough to stick around\n",
    "\n",
    "lasso_model = Lasso(alpha = .1)\n",
    "lasso_model.fit(X_train.loc[:,selected_columns1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(selected_columns1, lasso_model.coef_))\n",
    "\n",
    "# CHI, LAL, PHO & SAC were kept in as positive coefficient dummy variables, the rest were discarded after Lasso treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns(['ATL', 'BOS', 'BRK', 'CHA', 'CHO', 'CLE', 'DAL', 'DEN', 'DET',\n",
    "       'GSW', 'HOU', 'IND', 'LAC', 'MEM', 'MIA', 'MIL', 'NOH', 'NOP',\n",
    "       'NYK', 'OKC', 'ORL', 'PHI', 'POR', 'SAS', 'TOR', 'UTA',\n",
    "       'WAS','opp'],avg_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resaving my final data table back to pickle form for safe keeping\n",
    "\n",
    "avg_data_table.to_pickle('wolves_data_table.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.set(font_scale = 1.4)\n",
    "# sns.set_style(\"ticks\",{'xtick.major_size':2})\n",
    "sns.pairplot(avg_data_table)\n",
    "# plt.title('Def. Rebounds vs. Plus/Minus')\n",
    "# plt.xlabel(\"Defensive Rebounds\")\n",
    "# plt.ylabel('Plus / Minus')\n",
    "plt.savefig('pairplot.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_data_table['days_rest*2p_avg'] = avg_data_table['_2p_avg'] * avg_data_table['days_rest']\n",
    "avg_data_table['opp_2p_avg*opp_3p_avg'] = avg_data_table['opp_2p_avg'] * avg_data_table['opp_3p_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = avg_data_table.drop(['plus_minus'],axis=1), avg_data_table['plus_minus']\n",
    "\n",
    "# keep 20% of the data for final testing\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['home', 'orb_pct_avg', '2p_avg', '3p_avg',\n",
    "       'ft_avg', 'ast_avg', 'tov_avg', 'pf_avg', 'opp_2p_avg', 'opp_3p_avg',\n",
    "       'opp_ft_avg', 'opp_tov_avg', 'opp_pf_avg', 'drb_avg', 'days_rest',\n",
    "      '2p_avg*days_rest','opp_2p_avg*opp_3p_avg', 'CHI', 'LAL', 'PHO', 'SAC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "#Standard scaler to enable Ridge\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#tranforming train, val, & test to run poly model for each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running linear, ridge and polynomial regression to see what works on the model moving forward\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_validate(X, y):\n",
    "    '''\n",
    "    For a set of features and target X, y, perform a 80/20 train/val split, \n",
    "    fit and validate a linear regression model, and report results\n",
    "    '''\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # perform train/val split\n",
    "    X_train, X_val, y_train, y_val = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "    X_val_scaled = scaler.transform(X_val.values)\n",
    "    \n",
    "    # fit linear regression to training data\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # score fit model on validation data\n",
    "    val_score = lr_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    # getting the results\n",
    "    print('\\nValidation R^2 score was:', val_score)\n",
    "    print('Feature coefficient results: \\n')\n",
    "    for feature, coef in zip(X.columns, lr_model.coef_):\n",
    "        print(feature, ':', f'{coef:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_validate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to run the cross validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 21)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge regression with scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "#simple and ridge regression scores\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "#linear & ridge regression mean Cross validation r-squares\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our final test results with linear regression\n",
    "\n",
    "lm.fit(X,y)\n",
    "print(f'Linear Regression test R^2: {lm.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_model = sm.OLS(y, X, data=avg_data_table)\n",
    "\n",
    "results = avg_model.fit()\n",
    "\n",
    "# summarize our model\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
